{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugpBVO_qtCj0"
      },
      "source": [
        "<h3>Notebook for Contrastive Learning and Drum Experimentations<h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Kk4js3wtF8k"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4C94urYtQJ7"
      },
      "outputs": [],
      "source": [
        "%cd drive/MyDrive/SSLMB/\n",
        "%ls "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGYa2sMJuImX"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install stempeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rewfOLo4VW6"
      },
      "source": [
        "<h4>Step 1: import the packages and functions we need.<h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QeiJJrctCj4"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import random\n",
        "import torch\n",
        "import stempeg\n",
        "\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa           as audio_lib\n",
        "import IPython.display   as ipd\n",
        "\n",
        "import processing.input_rep as IR\n",
        "\n",
        "from models.models import Pretext_CNN\n",
        "\n",
        "from spleeter.separator import Separator\n",
        "import processing.source_separation as source_separation\n",
        "\n",
        "fp_musdb18 = \"Jupyter Data Sets/musdb18/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmMFc3IptCj6"
      },
      "source": [
        "<h5>The following functions are used to verify whether a signal contains drums, and more importantly make sure that these aren't too overbearing compared to the rest of the signal. These are used to pre-process our stems for the pretext task.<h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oLZh_c4tCj7"
      },
      "outputs": [],
      "source": [
        "def compute_rms(signal):\n",
        "    \"\"\"\n",
        "    Function for combining a signal's Root Mean Square (RMS) value.\n",
        "    -- signal : input waveform\n",
        "    \"\"\"\n",
        "    rms = audio_lib.feature.rms(y=signal, frame_length=2048, hop_length=512)\n",
        "\n",
        "    # Compute mean and standard deviations of rms for stems\n",
        "    mean_rms = np.mean(rms)\n",
        "    std_rms  = np.std(rms)\n",
        "\n",
        "    return rms, mean_rms, std_rms\n",
        "\n",
        "\n",
        "def check_drum_stem(drums, other, low_bound):\n",
        "    \"\"\"\n",
        "    Function for thresholding drums. Goal is to make sure drum clip has enough energy.\n",
        "    -- drums     : drum signal\n",
        "    -- other     : rest of song signal\n",
        "    -- low_bound : lower percentage bound\n",
        "    \"\"\"\n",
        "    ros_rms,  _, _ = compute_rms(other)\n",
        "    drum_rms, _, _ = compute_rms(drums)\n",
        "\n",
        "    rms_check1 = drum_rms[:] > ros_rms[:] / 2\n",
        "    rms_check2 = drum_rms[:] < ros_rms[:] * 4\n",
        "    rms_check1 = rms_check1.astype(int)[0]\n",
        "    rms_check2 = rms_check2.astype(int)[0]\n",
        "    rms_check  = rms_check1[:] * rms_check2[:]\n",
        "    rms_sum    = np.sum(rms_check)\n",
        "    rms_perc   = rms_sum / len(rms_check)\n",
        "\n",
        "    if (low_bound < rms_perc < 1.):\n",
        "        return True, rms_perc\n",
        "    \n",
        "    else:\n",
        "        return False, rms_perc\n",
        "\n",
        "    \n",
        "def takeSecond(elem):\n",
        "    \"\"\"\n",
        "    Function that returns second element of list or tuple. Used to sort list of tuples by second element later on.\n",
        "    elem : tuple or list\n",
        "    \"\"\"\n",
        "    return elem[1]\n",
        "\n",
        "\n",
        "def gen_vqt(signal, sample_rate):\n",
        "    \"\"\"\n",
        "    Generates a high-resolution XQT spectrogram.\n",
        "    -- signal      : signal to compute XQT on\n",
        "    -- sample_rate : self-explanatory \n",
        "    \"\"\"\n",
        "    hop_length  = 256\n",
        "    first_note  = 'C0'\n",
        "    octave_reso = 12\n",
        "    num_octaves = 8\n",
        "\n",
        "    fmin = audio_lib.note_to_hz(first_note)\n",
        "\n",
        "    VQT = audio_lib.vqt(y=signal, sr=sample_rate, hop_length=hop_length, fmin=fmin, \n",
        "                        n_bins=num_octaves*octave_reso, bins_per_octave=octave_reso)\n",
        "    \n",
        "    return VQT\n",
        "\n",
        "def plot_vqt(signal, sample_rate, title, colorbar=False, axis=False, save=None):\n",
        "    \"\"\"\n",
        "    Generates a high-resolution XQT spectrogram.\n",
        "    -- signal      : signal to compute XQT on\n",
        "    -- sample_rate : self-explanatory \n",
        "    \"\"\"\n",
        "    hop_length  = 256\n",
        "    first_note  = 'C0'\n",
        "    octave_reso = 12\n",
        "    num_octaves = 8\n",
        "\n",
        "    fmin = audio_lib.note_to_hz(first_note)\n",
        "\n",
        "    VQT = audio_lib.vqt(y=signal, sr=sample_rate, hop_length=hop_length, fmin=fmin, \n",
        "                        n_bins=num_octaves*octave_reso, bins_per_octave=octave_reso)\n",
        "    \n",
        "    VQT = np.abs(VQT)\n",
        "\n",
        "    VQT = np.log(0.1 + VQT)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    img = audio_lib.display.specshow(VQT, hop_length=hop_length,\n",
        "                                     sr=sample_rate, x_axis='time', y_axis='cqt_note', ax=ax, cmap='gray_r')\n",
        "    \n",
        "    if (title != None):\n",
        "        ax.set_title(title)\n",
        "\n",
        "    if (colorbar == True):\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "    if (axis == False):\n",
        "        plt.axis('off')\n",
        "\n",
        "    if (save != None):\n",
        "        plt.savefig(save, dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "# Load the separation model:\n",
        "spl_mod   = \"4stems\"\n",
        "m         = 'spleeter:{}'.format(spl_mod)\n",
        "separator = Separator(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A08apSmItCj7"
      },
      "outputs": [],
      "source": [
        "%ls Jupyter\\ Data\\ Sets/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTWpITcwtCj8"
      },
      "source": [
        "<h4>Step 2: import XX second stems. Load signals and log VQTs from MUS DB data set.<h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW0xUL9NtCj9"
      },
      "outputs": [],
      "source": [
        "# Can be 5 or 10\n",
        "XX = 10\n",
        "\n",
        "if (XX == 5):\n",
        "    VQT_len = 313\n",
        "\n",
        "else:\n",
        "    VQT_len = 626\n",
        "\n",
        "mus_train = os.listdir(fp_musdb18 + 'train/')\n",
        "mus_test  = os.listdir(fp_musdb18 + 'test/')\n",
        "\n",
        "len_musdb = len(mus_train) + len(mus_test)\n",
        "\n",
        "musdb = np.zeros((150, 3, 96, VQT_len))\n",
        "\n",
        "full__signals = np.zeros((150, XX * 16000))\n",
        "drums_signals = np.zeros((150, XX * 16000))\n",
        "other_signals = np.zeros((150, XX * 16000))\n",
        "\n",
        "low_bound = 0.3\n",
        "\n",
        "idx = 0\n",
        "for fp in mus_train:\n",
        "    S, rate = stempeg.read_stems(fp_musdb18 + 'train/' + fp, stem_id=[0], sample_rate=44100)\n",
        "    \n",
        "    stems = source_separation.wv_run_spleeter(S, rate, separator, spl_mod)\n",
        "\n",
        "    S = (S[:, 0] + S[:, 1]) / 2\n",
        "    \n",
        "    drums = np.zeros((S.shape[0]))\n",
        "    other = np.zeros((S.shape[0]))\n",
        "        \n",
        "    drums[:] = (stems['drums'][:, 0] + stems['drums'][:, 1]) / 2\n",
        "    other[:] = (stems['other'][:, 0] + stems['other'][:, 1] + stems['vocals'][:, 0] + stems['vocals'][:, 1]\n",
        "              + stems['bass'][:, 0] + stems['bass'][:, 1] ) / 2\n",
        "    \n",
        "    stem_status = False\n",
        "    \n",
        "    iters = 0\n",
        "    while (stem_status == False):\n",
        "        if (iters > 25):\n",
        "            break\n",
        "            \n",
        "        temp_idx    = random.randint(0, len(drums) - XX * rate - 1)\n",
        "        \n",
        "        temp_drums  = drums[temp_idx:temp_idx + XX * rate]\n",
        "        temp_other  = other[temp_idx:temp_idx + XX * rate]\n",
        "        \n",
        "        stem_status, stem_pow = check_drum_stem(temp_drums, temp_other, low_bound)\n",
        "        \n",
        "        iters += 1\n",
        "        \n",
        "    if (stem_status == False):\n",
        "        continue\n",
        "\n",
        "    temp__full = S[temp_idx:temp_idx + XX * rate]\n",
        "    temp__full = audio_lib.resample(temp__full, 44100, 16000)\n",
        "    temp_drums = audio_lib.resample(temp_drums, 44100, 16000)\n",
        "    temp_other = audio_lib.resample(temp_other, 44100, 16000)\n",
        "                    \n",
        "    VQT_drums = IR.generate_XQT(temp_drums, 16000, 'vqt')\n",
        "    VQT_other = IR.generate_XQT(temp_other, 16000, 'vqt')\n",
        "    VQT__full = IR.generate_XQT(temp__full, 16000, 'vqt')\n",
        "    \n",
        "    drums_signals[idx, :] = temp_drums[:]\n",
        "    other_signals[idx, :] = temp_other[:]\n",
        "    full__signals[idx, :] = temp__full[:]\n",
        "    \n",
        "    musdb[idx, 0, :, :] = VQT_other[:, :]\n",
        "    musdb[idx, 1, :, :] = VQT_drums[:, :]\n",
        "    musdb[idx, 2, :, :] = VQT__full[:, :]\n",
        "        \n",
        "    print(\"{} -- {} : RMS Pow% is {:.3f}.\".format(idx, 'train/' + fp, stem_pow))\n",
        "    \n",
        "    idx += 1\n",
        "        \n",
        "for fp in mus_test:\n",
        "    S, rate = stempeg.read_stems(fp_musdb18 + 'test/' + fp, stem_id=[0], sample_rate=44100)\n",
        "    \n",
        "    stems = source_separation.wv_run_spleeter(S, rate, separator, spl_mod)\n",
        "\n",
        "    S = (S[:, 0] + S[:, 1]) / 2\n",
        "    \n",
        "    drums = np.zeros((S.shape[0]))\n",
        "    other = np.zeros((S.shape[0]))\n",
        "        \n",
        "    drums[:] = (stems['drums'][:, 0] + stems['drums'][:, 1]) / 2\n",
        "    other[:] = (stems['other'][:, 0] + stems['other'][:, 1] + stems['vocals'][:, 0] + stems['vocals'][:, 1]\n",
        "              + stems['bass'][:, 0] + stems['bass'][:, 1] ) / 2\n",
        "    \n",
        "    stem_status = False\n",
        "    \n",
        "    iters = 0\n",
        "    while (stem_status == False):\n",
        "        if (iters > 25):\n",
        "            break\n",
        "            \n",
        "        temp_idx    = random.randint(0, len(drums) - XX * rate - 1)\n",
        "        \n",
        "        temp_drums  = drums[temp_idx:temp_idx + XX * rate]\n",
        "        temp_other  = other[temp_idx:temp_idx + XX * rate]\n",
        "        \n",
        "        stem_status, stem_pow = check_drum_stem(temp_drums, temp_other, low_bound)\n",
        "        \n",
        "        iters += 1\n",
        "        \n",
        "    if (stem_status == False):\n",
        "        continue\n",
        "\n",
        "    temp__full = S[temp_idx:temp_idx + XX * rate]\n",
        "    temp__full = audio_lib.resample(temp__full, 44100, 16000)\n",
        "    temp_drums = audio_lib.resample(temp_drums, 44100, 16000)\n",
        "    temp_other = audio_lib.resample(temp_other, 44100, 16000)\n",
        "                    \n",
        "    VQT_drums = IR.generate_XQT(temp_drums, 16000, 'vqt')\n",
        "    VQT_other = IR.generate_XQT(temp_other, 16000, 'vqt')\n",
        "    VQT__full = IR.generate_XQT(temp__full, 16000, 'vqt')\n",
        "    \n",
        "    drums_signals[idx, :] = temp_drums[:]\n",
        "    other_signals[idx, :] = temp_other[:]\n",
        "    full__signals[idx, :] = temp__full[:]\n",
        "    \n",
        "    musdb[idx, 0, :, :] = VQT_other[:, :]\n",
        "    musdb[idx, 1, :, :] = VQT_drums[:, :]\n",
        "    musdb[idx, 2, :, :] = VQT__full[:, :]\n",
        "        \n",
        "    print(\"{} -- {} : RMS Pow% is {:.3f}.\".format(idx, 'test/' + fp, stem_pow))\n",
        "    \n",
        "    idx += 1\n",
        "    \n",
        "temp_musdb = np.zeros((idx, 3, 96, VQT_len))\n",
        "\n",
        "temp_drums_signals = np.zeros((idx, XX * 16000))\n",
        "temp_other_signals = np.zeros((idx, XX * 16000))\n",
        "temp_full__signals = np.zeros((idx, XX * 16000))\n",
        "\n",
        "temp_musdb[:, :, :, :] = musdb[:idx, :, :, :]\n",
        "\n",
        "temp_drums_signals = drums_signals[:idx, :]\n",
        "temp_other_signals = other_signals[:idx, :]\n",
        "temp_full__signals = full__signals[:idx, :]\n",
        "\n",
        "musdb = temp_musdb\n",
        "\n",
        "drums_signals = temp_drums_signals\n",
        "other_signals = temp_other_signals\n",
        "full__signals = temp_full__signals\n",
        "        \n",
        "musdb = torch.from_numpy(musdb)\n",
        "print(\"MUS DB bank shape is : {}.\".format(musdb.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs1Ujc3FtCkB"
      },
      "source": [
        "<h4>Step 3: load pretext task model on cpu or gpu.<h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRrefWOXtCkD"
      },
      "outputs": [],
      "source": [
        "# Load pretext task model weights\n",
        "device     = torch.device('cpu')\n",
        "model      = Pretext_CNN(pretext=False)\n",
        "state_dict = torch.load(\"models/saved/shift_pret_cnn_16.pth\", map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "if (torch.cuda.is_available() == True):\n",
        "    model = model.cuda()\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6ltWnoxczRc"
      },
      "source": [
        "<h4>Step 4: compute embeddings for percussive and non-percussive signals. Plot and listen for fun!<h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMmKgUAVczRc"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Randomly select an anchor \n",
        "anchor_idx = random.randint(0, len(musdb) - 1)\n",
        "\n",
        "print(\"Randomly chosen index is : {}.\".format(anchor_idx))\n",
        "\n",
        "# Compute model output for anchor\n",
        "anchor     = musdb[anchor_idx, 0, :, :].reshape((1, 1, musdb.shape[2], musdb.shape[3]))\n",
        "\n",
        "if (torch.cuda.is_available() == True):\n",
        "    anchor = anchor.cuda()\n",
        "    anchor_emb = model.anchor(anchor.float())\n",
        "\n",
        "else:\n",
        "    anchor_emb = model.anchor(anchor.float())\n",
        "\n",
        "# Compute model output for all positives\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
        "\n",
        "if (torch.cuda.is_available == True):\n",
        "    cos = cos.cuda()\n",
        "\n",
        "l = []\n",
        "\n",
        "pos_idx = anchor_idx\n",
        "\n",
        "positive     = musdb[pos_idx, 1, :, :].reshape((1, 1, musdb.shape[2], musdb.shape[3]))\n",
        "\n",
        "if (torch.cuda.is_available() == True):\n",
        "    positive = positive.cuda()\n",
        "    positive_emb = model.postve(positive.float())\n",
        "\n",
        "else:\n",
        "    positive_emb = model.postve(positive.float())\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "cos_output = cos(anchor_emb, positive_emb)\n",
        "\n",
        "print(\"\\nCosine similarity  between anchor and positive is: {:.3f}.\".format(float(cos_output)))\n",
        "        \n",
        "ipd.display(ipd.Audio(drums_signals[pos_idx], rate=16000))\n",
        "ipd.display(ipd.Audio(other_signals[anchor_idx], rate=16000))\n",
        "ipd.display(ipd.Audio(other_signals[anchor_idx] + drums_signals[pos_idx], rate=16000))\n",
        "\n",
        "if (torch.cuda.is_available() == True):\n",
        "    positive = positive.cuda()\n",
        "    positive_emb = model.postve(positive.float())\n",
        "else:\n",
        "    positive_emb = model.postve(positive.float())\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
        "\n",
        "#########################################################\n",
        "print(\"\\nPlots for Results section:\")\n",
        "\n",
        "if (torch.cuda.is_available() == True):\n",
        "    plt.plot(anchor_emb.cpu().detach().numpy().reshape(VQT_len))\n",
        "    plt.plot(positive_emb.cpu().detach().numpy().reshape(VQT_len))\n",
        "else:\n",
        "    plt.plot(anchor_emb.detach().numpy().reshape(VQT_len))\n",
        "    plt.plot(positive_emb.detach().numpy().reshape(VQT_len))\n",
        "plt.legend([\"Non-percussive\", \"Percussive\"])\n",
        "plt.xlabel(\"Time (samples)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.ylim((-0.1, 1))\n",
        "plt.yticks([0., 0.25, 0.5, 0.75, 1.0])\n",
        "plt.show()\n",
        "\n",
        "x1 = np.linspace(0, XX, XX * 16000)\n",
        "x2 = np.linspace(0, XX, VQT_len)\n",
        "\n",
        "plt.plot(x1, drums_signals[pos_idx])\n",
        "if (torch.cuda.is_available() == True):\n",
        "    plt.plot(x2, positive_emb.cpu().detach().numpy().reshape(VQT_len))\n",
        "else:\n",
        "    plt.plot(x2, positive_emb.detach().numpy().reshape(VQT_len))\n",
        "plt.legend([\"Signal\", \"Embedding\"])\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.ylim((-1, 1))\n",
        "plt.yticks([-1.0, -0.5, 0., 0.5, 1.0])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x1, other_signals[anchor_idx])\n",
        "if (torch.cuda.is_available() == True):\n",
        "    plt.plot(x2, anchor_emb.cpu().detach().numpy().reshape(VQT_len))\n",
        "else:\n",
        "    plt.plot(x2, anchor_emb.detach().numpy().reshape(VQT_len))\n",
        "plt.legend([\"Signal\", \"Embedding\"])\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.ylim((-1, 1))\n",
        "plt.yticks([-1.0, -0.5, 0., 0.5, 1.0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdN-ariOK-Ls"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "drum_playground.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
